# -*- coding: utf-8 -*-
"""SNN_speech_recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JEJyMAbgBOmRyYZRf9gdCEv_yJHFR3bx
"""

## Install the dependencies which are not imbuilt in Google colab
!pip install pyspike
!pip install python_speech_features
!pip install neuronpy
!pip install pydrive

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.pyplot import plot
from random import shuffle
import os
import sys
import pyspike as spk
import sys
from pyspike import SpikeTrain
from datetime import datetime
import copy
import math
import ntpath
from scipy.fftpack import fft
from scipy.io import wavfile
from numpy.lib import stride_tricks
from python_speech_features.sigproc import framesig
import random as random
from matplotlib.pyplot import specgram
import wave
import contextlib
from google.colab import files
import zipfile
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# 1. Authenticate and create the PyDrive client. This drive must contain the data
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)
print(drive)
print("auth success")

global prototype_trains
global test_trains

class izhikevich:

    def __init__(self):
        # pre_syn and post_syn are the pre and post synapse times. synapses array hold the list of synapses associated with a neuron
        ## The below values are as mentioned in the paper
        self.pre_syn = []
        self.post_syn = []
        self.synapses = []
        self.v_rest = -60
        self.v_threshold = -40
        self.v_peak = 35
        self.C = 100
        self.K = 0.7
        self.a=0.03
        self.b = -2
        self.c = -50
        self.d = 100


    def neuron_simulation(self, time_ita, current):
        # a,b,c,d parameters for Izhikevich model
        # time_ita time iterations for euler method
        # current list of current for each time step
        
        spike_times = []
        v = self.c     #v_init
        #u = v * self.b
        u = 0
        v_plt = np.zeros(time_ita)
        u_plt = np.zeros(time_ita)
        spike = np.zeros(time_ita)
        num_spikes = 0
        tstep = 0.1  # ms
        ita = 0
        while ita < time_ita:
            v_plt[ita] = v
            u_plt[ita] = u
            ## The formula to follow
            # dt = tstep
            # dU/dt = a * (b * (V - v_rest) - u)
            # dV/dt = (K/C)*(V-v_rest)*(V-v_threshold) - U/C + current[ita]/C
            
            v += tstep * ((self.K/self.C)*(v-self.v_rest)*(v-self.v_threshold)-u/self.C + current[ita]/self.C)
            u += tstep * self.a * (self.b * (v - self.v_rest) - u)
            if v > self.v_peak:	#If goes above v_peak, the spikes and v reset back to initial conditions.
                spike[ita] = 1
                num_spikes += 1
                v = self.c
                u += self.d


            ita += 1
        time = np.arange(time_ita) * tstep
        i = 0
        for t in time:
            if spike[i] == 1:
                spike_times.append(t)
            i += 1
        return time, v_plt, spike, num_spikes, spike_times

    def append_pre_synapse_times(self, times):
        self.pre_syn = times

    def append_post_synapse_times(self, times):
        self.post_syn = times

    def append_synapse(self, synapse):
        self.synapses.append(synapse)

class Network:

    def __init__(self, weights):
        
        self.time_ita = 200  # 100ms
        # Build a layer of 200 input neurons 
        self.input_layer = []
        for i in range(200):
            n = izhikevich()
            self.input_layer.append(n)

        # Build output layer, one neuron for each digit 
        self.output_layer = []
        for i in range(10):
            o = izhikevich()
            self.output_layer.append(o)
        i = 0
        # For each input neuron, append one synapse to each output neuron
        for n in self.input_layer:
            for out in self.output_layer:
                synapse = Synapse()
                n.append_synapse(synapse)
                out.append_synapse(synapse)

        if weights is not None:  # weights == None means the call from train()
            i = 0
            n = 0
            s = 0
            with open(weights) as f:
                for line in f:
                    # For every 200 synapses, go to the next neuron
                    if i % 200 == 0 and n < len(self.output_layer):
                        s = 0
                        out = self.output_layer[n]
                        n += 1
                        out.synapses[s].set_weight(line)
                        s += 1
                    elif s < 200:
                        out.synapses[s].set_weight(line)
                        s += 1
                    i += 1

    # Calculates the current from the feature
    def get_current(self, x):
        return x

    def get_total(self, neuron):
        g_tot = 0
        for synapse in neuron.synapses:
            t = 0
            i = 0
            tau = 2
            for j in synapse.spike:
                if j == 1:
                    t_kj = synapse.time[i]
                    t = np.abs(t - t_kj)
                    g_tot += synapse.w * (t - t_kj) * np.exp(-(t - t_kj) / tau)
                    t = t_kj
                i += 1
        return g_tot

    # Get the total synaptic output for this neuron
    def total_synaptic_value(self, neuron):
        conductance = 0
        for syn_k in neuron.synapses:
            output = syn_k.synapse(2)
            conductance += output
        return conductance

    # if result == 0, then our target neuron is the first neuron in the output layer
    # result == 1 --> 2nd output neuron, result == 3 --> 3rd output neuron and so on
    def conduct_training(self, result):
        i = 0
        for out in self.output_layer:
            if i == result:
                # Undergo Hebbian STDP
                for syn in out.synapses:
                    syn.Heb_STDP()
            else:
                # Undergo anti-Hebbian STDP for non-target synapses
                for syn in out.synapses:
                    syn.Anti_Heb_STDP()
            i += 1


    def start(self, fname):

        features = Utils.get_features(fname)
        features = features[:200]
        
        #Feed features into our network and get spike information (number of spikes, time of largest spike)
        i = 0

        # Use feature for 200 input neurons
        for feature in features:
            n = self.input_layer[i]
            current = np.ones(self.time_ita) * self.get_current(feature)
            #spike has 1 at time steps a spike occurred and 0 wherever no spike. 
            #spike_times is an array of the time steps when a spike occurred
            #v_plt is an array containing voltage value at each time step.
            # time is an array of the time steps
            time, v_plt, spike, num_spikes, spike_times = n.neuron_simulation(self.time_ita, current)
            
            # Set pre spikes for each synapse connected to this neuron
            for synapse in n.synapses:
                synapse.set_pre_spikes(spike_times)
                synapse.set_time(time)
                synapse.set_spike(spike)
            i += 1


        # Create a 10 neuron output vector
        outputs = [0] * 10
        spikes = []
        v_plts = []
        currents = []
        i = 0
        for out in self.output_layer:
            current = np.ones(200) * self.total_synaptic_value(out)
            time, v_plt, spike, num_spikes, spike_times = out.neuron_simulation(self.time_ita, current)
            spikes.append(spike_times)
            v_plts.append(v_plt)
            currents.append(current)
            for syn in out.synapses:
                syn.set_post_spikes(spike_times)

            outputs[i] = num_spikes
            i += 1

        return outputs, currents, time, v_plts, spikes

class Synapse:

    global spike, time, conductance_amplitude, w, spikes_received, pre_spikes, post_spikes, input_neuron, out_neuron

    def __init__(self):
        self.post_spikes = []
        self.pre_spikes = []
        self.w = random.uniform(0, 1)     ## Initial weights is set to 0.5 //ASSUMPTION!!!

    def set_weight(self, w):
        self.w = float(w)

    def set_time(self, time):
        self.time = time

    def set_spike(self, spike):
        self.spike = spike

    def set_pre_spikes(self, pre_spikes):
        self.pre_spikes = pre_spikes

    def set_post_spikes(self, post_spikes):
        self.post_spikes = post_spikes

    # Our W function for Hebbian STDP
    def heb_delta(self, delta_t):
        tau_pre = 2
        tau_post = 2
        Apre = .1
        Apost = -Apre
        if delta_t >= 0:
            return Apre*np.exp(-np.abs(delta_t)/tau_pre)
        if delta_t < 0:
            return Apost*np.exp(-np.abs(delta_t)/tau_post)

    # Our W function for anti-Hebbian STDP
    def anti_heb_delta(self, delta_t):
        tau_pre = 2
        tau_post = 2
        Apre = .1
        Apost = -Apre
        if delta_t < 0:
            return Apre*np.exp(-np.abs(delta_t)/tau_pre)
        if delta_t >= 0:
            return Apost*np.exp(-np.abs(delta_t)/tau_post)

    # Same as Hebbian STDP except the cases are reversed
    def Anti_Heb_STDP(self):
        delta_w = 0
        for t_pre in self.pre_spikes:
            for t_post in self.post_spikes:
                delta_w += self.anti_heb_delta(t_post - t_pre)
        
        self.w += delta_w
        if self.w < 0:
            self. w = 0
 

    # Change in synaptic weight is the sum over all presynaptic spike times (t_pre) and postsynaptic spike times (t_post)
    # of some function W of the difference in these spike times
    def Heb_STDP(self):
        delta_w = 0
        
        for t_pre in self.pre_spikes:
            for t_post in self.post_spikes:
                delta_w += self.heb_delta(t_post - t_pre)
        self.w += delta_w
        if self.w < 0:
            self.w = 0


    # Calculates synaptic output
    def synapse(self, tau):
        synapse_output = np.zeros(len(self.time))
        for t in range(len(self.time)):
            tmp_time = self.time[t] - self.time[0:t]
            synapse_output[t] = np.sum(((tmp_time * self.spike[0:t]) / tau) * np.exp(-(tmp_time * self.spike[0:t]) / tau))
        return self.w * synapse_output

    def synapse_func(self, tau):
        time = np.arange(10000) * 0.1
        func = time / tau * np.exp(-time / tau)
        return time, func

class Utils:
    def get_features(file_name):
        (rate, sig) = wavfile.read(file_name)

        with contextlib.closing(wave.open(file_name, 'r')) as f:
            frames = f.getnframes()
            rate = f.getframerate()
            duration = frames / float(rate)

        # Frame our signal into 40 frames with 50% overlap
        number_of_frames = 40
        frame_len = len(sig) / (number_of_frames*(.5) + .5)
        frames = framesig(sig, frame_len, frame_len * .5)

        # A list of 40 frequency lists for each frame. 5 frequency bands with the average energy of each
        features = []
        band0 = []
        band1 = []
        band2 = []
        band3 = []
        band4 = []
        
        for frame in frames:
            spectrum, freqs, t, img = specgram(frame, Fs=rate)
            i = 0
            bands = []
            for freq in freqs:
                if freq <= 333.3:
                    band0.extend(spectrum[i])
                elif freq > 333.3 and freq <= 666.7:
                    band1.extend(spectrum[i])
                elif freq > 666.7 and freq <= 1333.3:
                    band2.extend(spectrum[i])
                elif freq > 1333.3 and freq <= 2333.3:
                    band3.extend(spectrum[i])
                elif freq > 2333.3 and freq <= 4000:
                    band4.extend(spectrum[i])

                i += 1
            bands.append(sum(band0) / len(band0))
            bands.append(sum(band1) / len(band1))
            bands.append(sum(band2) / len(band2))
            bands.append(sum(band3) / len(band3))
            bands.append(sum(band4) / len(band4))
            features.append(bands)

        values = []
        for feature in features:
            for f in feature:
                values.append(f)
        
        return values

   # Get label associated with this file
    def get_label(filename):
        
        head, tail = ntpath.split(filename)
        name = str(tail)
        label, rest1, rest2 = name.split('_')
        return label
      
    def plot_spikes(neuralData):
      
      colorCodes = np.array([[0,0,0,0],[0,1, 0, 0],[0,0, 1, 0],[0,0, 0, 1],[1,1,0,0],[1, 0, 1,0],[0, 1, 1,0],[0,1, 0, 1],[0,1,1,1],[1,1,1,1]])
      lineSize = [0.4, 0.3, 0.2, 0.8, 0.5, 0.6, 0.7, 0.9, 0.2, 0.5]                                  
      plt.eventplot(neuralData, color=colorCodes, linelengths = lineSize)  
      # Provide the title for the spike raster plot
      plt.title('Spike raster plot')
      # Give x axis label for the spike raster plot
      plt.xlabel('Neuron')
      # Give y axis label for the spike raster plot
      plt.ylabel('Spike')
      # Display the spike raster plot
      plt.show()

prototype_trains = [None] * 10
test_trains = [None] * 10

def write_weights(network):
    i = 0
    with open("weights.txt", "a") as f:
        for out in network.output_layer:
            if i == 0:
                f.write("0\n")
            elif i == 1:
                f.write("1\n")
            elif i == 2:
                f.write("2\n")
            elif i == 3:
                f.write("3\n")
            elif i == 4:
                f.write("4\n")
            elif i == 5:
                f.write("5\n")
            elif i == 6:
                f.write("6\n")
            elif i == 7:
                f.write("7\n")
            elif i == 8:
                f.write("8\n")
            elif i == 9:
                f.write("9\n")
           
            i += 1

def print_result(results):
    print('\t0: ' + str(results[0]))
    print('\t1: ' + str(results[1]))
    print('\t2: ' + str(results[2]))
    print('\t3: ' + str(results[3]))
    print('\t4: ' + str(results[4]))
    print('\t5: ' + str(results[5]))
    print('\t6: ' + str(results[6]))
    print('\t7: ' + str(results[7]))
    print('\t8: ' + str(results[8]))
    print('\t9: ' + str(results[9]))
    

# Generate a spike train from the given spike
def generate_prototypes(spike, key):
    print('generating prototype')
    #global prototype_trains
    spike_train = SpikeTrain(spike, [0.0, 100.0])
    if key == '0':
        prototype_trains[0] = spike_train
        print('current prototype')
        print(prototype_trains)
    elif key == '1':
        prototype_trains[1] = spike_train
        print('current prototype')
        print(prototype_trains)
    elif key == '2':
        prototype_trains[2] = spike_train
        print('current prototype')
        print(prototype_trains)
    elif key == '3':
        prototype_trains[3] = spike_train
        print('current prototype')
        print(prototype_trains)
    elif key == '4':
        prototype_trains[4] = spike_train
        print('current prototype')
        print(prototype_trains)
    elif key == '5':
        prototype_trains[5] = spike_train
        print('current prototype')
        print(prototype_trains)
    elif key == '6':
        prototype_trains[6] = spike_train
        print('current prototype')
        print(prototype_trains)
    elif key == '7':
        prototype_trains[7] = spike_train
        print('current prototype')
        print(prototype_trains)
    elif key == '8':
        prototype_trains[8] = spike_train
        print('current prototype')
        print(prototype_trains)
    elif key == '9':
        prototype_trains[9] = spike_train
        print('current prototype')
        print(prototype_trains)

# Generate a spike train from the given spike
def generate_test_signatures(spike, key):
    print('generating test train')
    #global test_trains
    spike_train = SpikeTrain(spike, [0.0, 100.0])
    if key == '0':
        test_trains[0] = spike_train
    elif key == '1':
        test_trains[1] = spike_train
    elif key == '2':
        test_trains[2] = spike_train
    elif key == '3':
        test_trains[3] = spike_train
    elif key == '4':
        test_trains[4] = spike_train
    elif key == '5':
        test_trains[5] = spike_train
    elif key == '6':
        test_trains[6] = spike_train
    elif key == '7':
        test_trains[7] = spike_train
    elif key == '8':
        test_trains[8] = spike_train
    elif key == '9':
        test_trains[9] = spike_train
        
def spike_analysis(spikes):
    distances = []
    numbers = ['0','1', '2','3','4','5','6','7','8','9']
    i = 0
    for spike in spikes:
        spike_train = SpikeTrain(spike, [0.0, 100.0])
        isi_profile = spk.spike_sync(prototype_trains[i], spike_train)
        print("\t%s: " % numbers[i] + str(isi_profile))
        distances.append(isi_profile)
        i += 1

    val, idx = max((val, idx) for (idx, val) in enumerate(distances))
    print("Distance: %.8f" % val)
    print("Index: %s" % numbers[idx])

def show_plots(time, v_plts, currents, spikes):
    
    plt.figure('0')
    plt.plot(time, v_plts[0], 'g-')
    plt.figure('1')
    plt.plot(time, v_plts[1], 'b-')
    plt.figure('2')
    plt.plot(time, v_plts[2], 'k-')
    plt.figure('3')
    plt.plot(time, v_plts[3], 'r-')
    plt.figure('4')
    plt.plot(time, v_plts[4], 'm-')
    plt.figure('5')
    plt.plot(time, v_plts[5], 'c-')
    plt.figure('6')
    plt.plot(time, v_plts[4], 'y-')
    plt.figure('7')
    plt.plot(time, v_plts[5], 'w-')
    
    plt.eventplot(spikes)
    plt.title('show plot')
    plt.show()
    
# Test our network
def test():
    print('Testing started')
    global prototype_trains
    global test_trains
    prototype_trains = [None] * 10
    test_trains = [None] * 10
    mapping = dict()

    weights = "weights.txt"

    network = Network(weights=weights)
    
    prototype_dict = dict()
    ## Prototype data
    folder_id = 'xxx' ## This drive id
    audio = drive.ListFile({'q': "'%s' in parents" % folder_id}).GetList()  
    # should tell mimetype file you're trying download has.   
      
    mimetypes = {'application/vnd.google-apps.audio'}  
    for file1 in audio:
      download_mimetype = None
      if file1['mimeType'] in mimetypes:
          download_mimetype = mimetypes[file1['mimeType']]

      file1.GetContentFile(file1['title'], mimetype=download_mimetype)

    for file in audio:
        fname = file['title']
        prototype_dict[fname] = Utils.get_label(fname)
    
    ## Test data
    folder_id = 'xxx'
    audio = drive.ListFile({'q': "'%s' in parents" % folder_id}).GetList()  
    # should tell mimetype file you're trying download has.   
      
    mimetypes = {'application/vnd.google-apps.audio'}  
    for file1 in audio:
      download_mimetype = None
      if file1['mimeType'] in mimetypes:
          download_mimetype = mimetypes[file1['mimeType']]

      file1.GetContentFile(file1['title'], mimetype=download_mimetype)

    for file in audio:
        fname = file['title']
        mapping[fname] = Utils.get_label(fname)

    ## Create prototype trains
    _0_count = 1
    _1_count = 1
    _2_count = 1
    _3_count = 1
    _4_count = 1
    _5_count = 1
    _6_count = 1
    _7_count = 1
    _8_count = 1
    _9_count = 1
    
    count = 9
    prototype_array = []
    for key in prototype_dict:
        if prototype_dict[key] == '0' and _0_count != 0:
            print(key)
            results, currents, time, v_plts, spikes = network.start(key)
            prototype_array.append(spikes[0])
            #results has num of spikes of each output neuron
            print_result(results)
            _0_count -= 1
            count -= 1
            if _0_count == 0:
                # Generate a spike train for the '0' sound
                generate_prototypes(spikes[0], '0')

        elif prototype_dict[key] == '1' and _1_count != 0:
            print(key)
            results, currents, time, v_plts, spikes = network.start(key)
            prototype_array.append(spikes[1])
            print_result(results)
            _1_count -= 1
            count -= 1
            if _1_count == 0:
                # Generate a spike train for the '1' sound
                generate_prototypes(spikes[1], '1')

        elif prototype_dict[key] == '2' and _2_count != 0:
            print(key)
            results, currents, time, v_plts, spikes = network.start(key)
            prototype_array.append(spikes[2])
            print_result(results)
            _2_count -= 1                                                                              
            count -= 1
            if _2_count == 0:
                # Generate a spike train for the '2' sound
                generate_prototypes(spikes[2], '2')

        elif prototype_dict[key] == '3' and _3_count != 0:
            print(key)
            results, currents, time, v_plts, spikes = network.start(key)
            prototype_array.append(spikes[3])
            print_result(results)
            _3_count -= 1
            count -= 1
            if _3_count == 0:
                # Generate a spike train for the '3' sound
                generate_prototypes(spikes[3], '3')

        elif prototype_dict[key] == '4' and _4_count != 0:
            print(key)
            results, currents, time, v_plts, spikes = network.start(key)
            prototype_array.append(spikes[4])
            print_result(results)
            _4_count -= 1
            count -= 1
            if _4_count == 0:
                # Generate a spike train for the '4' sound
                generate_prototypes(spikes[4], '4')

        elif prototype_dict[key] == '5' and _5_count != 0:
            print(key)
            results, currents, time, v_plts, spikes = network.start(key)
            prototype_array.append(spikes[5])
            print_result(results)
            _5_count -= 1
            count -= 1
            if _5_count == 0:
                # Generate a spike train for the '5' sound
                generate_prototypes(spikes[5], '5')

        elif prototype_dict[key] == '6' and _6_count != 0:
            print(key)
            results, currents, time, v_plts, spikes = network.start(key)
            prototype_array.append(spikes[6])
            print_result(results)
            _6_count -= 1
            count -= 1
            if _6_count == 0:
                # Generate a spike train for the '6' sound
                generate_prototypes(spikes[6], '6')

        elif prototype_dict[key] == '7' and _7_count != 0:
            print(key)
            results, currents, time, v_plts, spikes = network.start(key)
            prototype_array.append(spikes[7])
            print_result(results)
            _7_count -= 1
            count -= 1
            if _7_count == 0:
                # Generate a spike train for the '7' sound
                generate_prototypes(spikes[7], '7')

        elif prototype_dict[key] == '8' and _8_count != 0:
            print(key)
            results, currents, time, v_plts, spikes = network.start(key)
            prototype_array.append(spikes[8])
            print_result(results)
            _8_count -= 1
            count -= 1
            if _8_count == 0:
                # Generate a spike train for the '8' sound
                generate_prototypes(spikes[8], '8')

        elif prototype_dict[key] == '9' and _9_count != 0:
            print(key)
            results, currents, time, v_plts, spikes = network.start(key)
            prototype_array.append(spikes[9])
            print_result(results)
            _9_count -= 1
            count -= 1
            if _9_count == 0:
                # Generate a spike train for the '9' sound
                generate_prototypes(spikes[9], '9')
    
    # Display our prototype spike trains
    print('Display our prototype spike trains')
   # _prototype_trains = np.asarray(prototype_trains)   ## this is a null set as np.asarray can not convert a spike train to array
    temp = spk.isi_profile(prototype_trains)
    x_prototype_trains, y_prototype_trains = temp.get_plottable_data()
    print(prototype_array)
    Utils.plot_spikes(prototype_array)

    ## Testing and create test trains
    
    _0_count = 5
    _1_count = 5
    _2_count = 5
    _3_count = 5
    _4_count = 5
    _5_count = 5
    _6_count = 5
    _7_count = 5
    _8_count = 5
    _9_count = 5
    
    
    test_spike_array = []
    for key in mapping:
        if mapping[key] == '0' and _0_count != 0:
            print(key)
            results, currents, time, v_plts, spikes = network.start(key)
            test_spike_array.append(spikes[0])
            #results has num of spikes of each output neuron
            print_result(results)
            _0_count -= 1
            spike_analysis(spikes)
            if _0_count == 0:
                # Generate a spike train for the '0' sound
                generate_test_signatures(spikes[0], '0')
             
        elif mapping[key] == '1' and _1_count != 0:
            print(key)
            results, currents, time, v_plts, spikes = network.start(key)
            test_spike_array.append(spikes[1])
            print_result(results)
            _1_count -= 1
            spike_analysis(spikes)
            if _1_count == 0:
                # Generate a spike train for the '1' sound
                generate_test_signatures(spikes[1], '1')
                
        elif mapping[key] == '2' and _2_count != 0:
            print(key)
            results, currents, time, v_plts, spikes = network.start(key)
            test_spike_array.append(spikes[2])
            print_result(results)
            _2_count -= 1
            spike_analysis(spikes)
            if _2_count == 0:
                # Generate a spike train for the '2' sound
                generate_test_signatures(spikes[2], '2')
            
        elif mapping[key] == '3' and _3_count != 0:
            print(key)
            results, currents, time, v_plts, spikes = network.start(key)
            test_spike_array.append(spikes[3])
            print_result(results)
            _3_count -= 1
            spike_analysis(spikes)
            if _3_count == 0:
                # Generate a spike train for the '3' sound
                generate_test_signatures(spikes[3], '3')
            
        elif mapping[key] == '4' and _4_count != 0:
            print(key)
            results, currents, time, v_plts, spikes = network.start(key)
            test_spike_array.append(spikes[4])
            print_result(results)
            _4_count -= 1
            spike_analysis(spikes)
            if _4_count == 0:
                # Generate a spike train for the '4' sound
                generate_test_signatures(spikes[4], '4')
            
        elif mapping[key] == '5' and _5_count != 0:
            print(key)
            results, currents, time, v_plts, spikes = network.start(key)
            test_spike_array.append(spikes[5])
            print_result(results)
            _5_count -= 1
            spike_analysis(spikes)
            if _5_count == 0:
                # Generate a spike train for the '5' sound
                generate_test_signatures(spikes[5], '5')
            
        elif mapping[key] == '6' and _6_count != 0:
            print(key)
            results, currents, time, v_plts, spikes = network.start(key)
            test_spike_array.append(spikes[6])
            print_result(results)
            _6_count -= 1
            spike_analysis(spikes)
            if _6_count == 0:
                # Generate a spike train for the '6' sound
                generate_test_signatures(spikes[6], '6')
            
        elif mapping[key] == '7' and _7_count != 0:
            print(key)
            results, currents, time, v_plts, spikes = network.start(key)
            test_spike_array.append(spikes[7])
            print_result(results)
            _7_count -= 1
            spike_analysis(spikes)
            if _7_count == 0:
                # Generate a spike train for the '7' sound
                generate_test_signatures(spikes[7], '7')
            
        elif mapping[key] == '8' and _8_count != 0:
            print(key)
            results, currents, time, v_plts, spikes = network.start(key)
            test_spike_array.append(spikes[8])
            print_result(results)
            _8_count -= 1
            spike_analysis(spikes)
            if _8_count == 0:
                # Generate a spike train for the '8' sound
                generate_test_signatures(spikes[8], '8')
            
        elif mapping[key] == '9' and _9_count != 0:
            print(key)
            results, currents, time, v_plts, spikes = network.start(key)
            test_spike_array.append(spikes[9])
            print_result(results)
            _9_count -= 1
            spike_analysis(spikes)
            if _9_count == 0:
                # Generate a spike train for the '9' sound
                generate_test_signatures(spikes[9], '9')
       
    # Display our last round of test spikes
    print('Display our test spike trains')
    temp = spk.isi_profile(test_trains)
    x_test_trains, y_test_trains = temp.get_plottable_data()
    #_test_trains = np.asarray(test_trains)
    print(test_spike_array)
    Utils.plot_spikes(test_spike_array)
           

# Train the network
def train():
    print('training started')
    network = Network(weights=None)

    mapping = dict()
    folder_id = 'xxx'
    audio = drive.ListFile({'q': "'%s' in parents" % folder_id}).GetList()  
    # should tell mimetype file you're trying download has.   
      
    mimetypes = {'application/vnd.google-apps.audio'}  
    for file1 in audio:
      download_mimetype = None
      if file1['mimeType'] in mimetypes:
          download_mimetype = mimetypes[file1['mimeType']]

      file1.GetContentFile(file1['title'], mimetype=download_mimetype)

    shuffle(audio)

    # Get a mapping of labels to audio
    for file1 in audio:
        fname = file1['title']
        mapping[fname] = Utils.get_label(fname)

    print(datetime.now())
    
    ## Training
    
    for j in range(100): ##100 epochs
      _0_count = 40
      _1_count = 40
      _2_count = 40
      _3_count = 40
      _4_count = 40
      _5_count = 40
      _6_count = 40
      _7_count = 40
      _8_count = 40
      _9_count = 40
      i = 0
      for key in mapping:
          if(i%10 == 0):
              print(i)
          if mapping[key] == '0' and _0_count > 0:
              print(key)
              results, currents, time, v_plts, spikes = network.start(key)
              #print_result(results)
              network.conduct_training(0)
              _0_count -= 1
          elif mapping[key] == '1' and _1_count > 0:
              print(key)
              results, currents, time, v_plts, spikes = network.start(key)
              #print_result(results)
              network.conduct_training(1)
              _1_count -= 1
          elif mapping[key] == '2' and _2_count > 0:
              print(key)
              results, currents, time, v_plts, spikes = network.start(key)
              #print_result(results)
              network.conduct_training(2)
              _2_count -= 1
          elif mapping[key] == '3' and _3_count > 0:
              print(key)
              results, currents, time, v_plts, spikes = network.start(key)
              #print_result(results)
              network.conduct_training(3)
              _3_count -= 1
          elif mapping[key] == '4' and _4_count > 0:
              print(key)
              results, currents, time, v_plts, spikes = network.start(key)
              #print_result(results)
              network.conduct_training(4)
              _4_count -= 1
          elif mapping[key] == '5' and _5_count > 0:
              print(key)
              results, currents, time, v_plts, spikes = network.start(key)
              #print_result(results)
              network.conduct_training(5)
              _5_count -= 1
          elif mapping[key] == '6' and _6_count > 0:
              print(key)
              results, currents, time, v_plts, spikes = network.start(key)
              #print_result(results)
              network.conduct_training(6)
              _6_count -= 1
          elif mapping[key] == '7' and _7_count > 0:
              print(key)
              results, currents, time, v_plts, spikes = network.start(key)
              #print_result(results)
              network.conduct_training(7)
              _7_count -= 1
          elif mapping[key] == '8' and _8_count > 0:
              print(key)
              results, currents, time, v_plts, spikes = network.start(key)
              #print_result(results)
              network.conduct_training(8)
              _8_count -= 1
          elif mapping[key] == '9' and _9_count > 0:
              print(key)
              results, currents, time, v_plts, spikes = network.start(key)
              #print_result(results)
              network.conduct_training(9)
              _9_count -= 1

          i = i+1

    write_weights(network)
    print(datetime.now())

train()
test()
